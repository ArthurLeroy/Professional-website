<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="" />
  <meta name="author" content="Arthur LEROY (MAP5 - Université de Paris)" />
  <meta name="author" content="Servane GEY (MAP5 - Université de Paris)" />
  <meta name="author" content="Pierre LATOUCHE (MAP5 - Université de Paris)" />
  <meta name="author" content="Benjamin GUEDJ (INRIA - UCL)" />
  <title>Apprentissage de données fonctionnelles par modèles multi-tâches :    Application à la prédiction de performances sportives</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="slides_Rouen_files/reveal.js-3.3.0.1/css/reveal.css"/>



<link rel="stylesheet" href="slides_Rouen_files/reveal.js-3.3.0.1/css/theme/serif.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>

    <link rel="stylesheet" href="style.css"/>

<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

    
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Apprentissage de données fonctionnelles par modèles multi-tâches : <br> <font size="20"> Application à la prédiction de performances sportives </font></h1>
    <h2 class="author"><br /></h2>
    <h2 class="author">Arthur LEROY (MAP5 - Université de Paris)</h2>
    <h2 class="author">Servane GEY (MAP5 - Université de Paris)</h2>
    <h2 class="author">Pierre LATOUCHE (MAP5 - Université de Paris)</h2>
    <h2 class="author">Benjamin GUEDJ (INRIA - UCL)</h2>
    <h3 class="date">Groupe de travail en Statistique du LMRS - Rouen - 22/10/2020</h3>
</section>

<section class="slide level2">

<!-- ## Context -->
<!-- Traditional talent identification: -->
<!-- $\rightarrow$ <span class="emphasized">Best young athlete + coach intuition </span> -->
<!-- <br> -->
<!-- G. Boccia et al. (2017) : -->
<!-- > $\simeq$ **60% of 16 years old elite athletes** do not maintain their level of performance -->
<!-- Philip E. Kearney & Philip R. Hayes (2018) : -->
<!-- > $\simeq$ **only 10% ** of senior top 20  were -->
<!-- also top 20 before 13 years -->
<!-- ## Data -->
<!-- Performances from FF of Swimming members since 2002: -->
<!-- - **Irregular** time series -->
<!-- - Different number $N_i$ of observations between individuals -->
<!-- - Different observational timestamps $t_i^k$ -->
<!-- - <font color='green'>$N_i$</font> $\simeq x \times10^1$ -->
<!-- <center>![](images/data1.png){width=580}</center> -->
<!-- ## Data -->
<!-- Performances from FF of Swimming members since 2002: -->
<!-- - **Irregular** time series -->
<!-- - Different number $N_i$ of observations between individuals -->
<!-- - Different observational timestamps $t_i^k$ -->
<!-- - <font color='green'>$N_i$</font> $\simeq x \times10^1$ |   <font color='red'>$N$</font> $= \sum\limits_{i=1}^{M}$ <font color='green'>$N_i$</font> $\simeq x \times 10^5$ -->
<!-- <center>![](images/data2.png){width=580}</center> -->
<!-- ## Data -->
<!-- Performances from FF of Swimming members since 2002: -->
<!-- - **Irregular** time series -->
<!-- - Different number $N_i$ of observations between individuals -->
<!-- - Different observational timestamps $t_i^k$ -->
<!-- - <font color='green'>$N_i$</font> $\simeq x \times10^1$ |   <font color='red'>$N$</font> $= \sum\limits_{i=1}^{M}$ <font color='green'>$N_i$</font> $\simeq x \times 10^5$ -->
<!-- <center>![](images/data3.png){width=580}</center> -->
<!-- ## Curves clustering -->
<!-- Functional data $\simeq$ coefficients $\alpha_k$ of B-splines functions: -->
<!-- $$y_i(t) = \sum\limits_{k=1}^{K}{\alpha_k B_k(t)}$$ -->
<!-- <span class="emphasized">Clustering:</span> Algo **FunHDDC** (Gaussian mixture + EM) -->
<!-- *Bouveyron & Jacques - 2011* -->
<!-- <br> -->
<!-- Using the multidimensional version : curve + derivative -->
<!-- $\rightarrow$ Information about performance **level** and **trend** of improvement -->
<!-- ## Curve clustering -->
<!-- *Leroy et al. - 2018* -->
<!-- - Different patterns of progression -->
<!-- - Consistent groups for sports experts -->
<!-- <center>![](images/multclust_all.png){height=450 width=920}</center> -->
<!-- ## Curve clustering -->
<!-- *Leroy et al. - 2018* -->
<!-- - Different patterns of progression -->
<!-- - Consistent groups for sport experts -->
<!-- <center>![](images/multclust.png){height=450 width=920}</center> -->
<!-- ## New objectives -->
<!-- - Prediction of the future values of the progression curve -->
<!-- $\rightarrow$ Functional regression -->
<!-- - Quantification of prediction uncertainty -->
<!-- $\rightarrow$ Probabilistic framework -->
<!-- <center>![](images/gpfda_unique.png){width=600}</center> -->
<!-- ## Gaussian process regression -->
<!-- *Bishop - 2006  | Rasmussen & Williams - 2006* -->
<!-- GPR : a kernel method to estimate $f$ when: -->
<!-- $$y = f(x) +\epsilon$$ -->
<!-- $\rightarrow$ **No restrictions** on $f$ but a **prior probability**: -->
<!-- $$f \sim \mathcal{GP}(0,C(\cdot,\cdot))$$ -->
<!-- *An example of exponential kernel for the covariance function:* -->
<!-- $$cov(f(x),f(x'))= C(x,x') = \alpha exp(- \dfrac{1}{2\theta^2} |x - x'|^2)$$ -->
<!-- Kernel definition $\Rightarrow$ *prefered* properties on $f$ -->
<!-- ## Prediction -->
<!-- $\textbf{y}_{N+1} = (y_1,...,y_{N+1})$ has the following prior density: -->
<!--  $$\textbf{y}_{N+1} \sim \mathcal{N}(0, C_{N+1}), \ C_{N+1} = \begin{pmatrix} C_N & k_{N+1} \\ k_{N+1}^T & c_{N+1} \end{pmatrix}$$ -->
<!-- When the joint density is gaussian, so does the conditionnal dentisty: -->
<!--  $$y_{N+1}|\textbf{y}_{N}, \textbf{x}_{N+1} \sim \mathcal{N}(k^T \color{red}{C_N^{-1}}\textbf{y}_{N}, c_{N+1}- k_{N+1}^T  \color{red}{C_N^{-1}} k_{N+1})$$ -->
<!-- <br> -->
<!-- - <span class="emphasized">Prediction:</span> $\hat{y}_{N+1} = \mathbb{E}[y_{N+1}|\textbf{y}_{N}, \textbf{x}_{N+1}]$ -->
<!-- - <span class="emphasized">Uncertainty:</span> CI with $\mathbb{V}[y_{N+1}|\textbf{y}_{N}, \textbf{x}_{N+1}]$ -->
<!-- ## Visualization of GPR -->
<!-- <center>![](images/GP.png)</center> -->
<!-- **Key points:** -->
<!-- - Define a covariance function with desirable properties -->
<!-- - Non parametric method giving probabilistic predictions -->
<!-- - Complexity $O(\color{red}{N^3})$ (inversion of an $\color{red}{N} \times \color{red}{N}$ matrix) -->
<!-- ## GP estimation from data -->
<!-- Estimating a GP on each individual ($O(\color{green}{N_i^3})$): -->
<!-- - <span class="emphasized">Uncertainty:</span> Ok -->
<!-- <center>![](images/gpfda_1pts.png){height=500}</center> -->
<!-- ## GP estimation from data -->
<!-- Estimating a GP on each individuals ($O(\color{green}{N_i^3})$): -->
<!-- - <span class="emphasized">Uncertainty:</span> Ok -->
<!-- <center>![](images/gpfda_5pts.png){height=500}</center> -->
<!-- ## GP estimation from data -->
<!-- Estimating a GP on each individuals ($O(\color{green}{N_i^3})$): -->
<!-- - <span class="emphasized">Uncertainty:</span> Ok -->
<!-- <center>![](images/gpfda_10pts.png){height=500}</center> -->
<!-- ## GP estimation from data -->
<!-- Estimating a GP on each individuals ($O(\color{green}{N_i^3})$): -->
<!-- - <span class="emphasized">Uncertainty:</span> Ok -->
<!-- <center>![](images/gpfda_15pts.png){height=500}</center> -->
<!-- ## GP estimation from data -->
<!-- Estimating a GP on each individuals ($O(\color{green}{N_i^3})$): -->
<!-- - <span class="emphasized">Uncertainty:</span> Ok -->
<!-- <center>![](images/gpfda_totalpts.png){height=500}</center> -->
<!-- ## Reaching a coherent modeling -->
<!-- Estimating a GP on each individuals ($O(\color{green}{N_i^3})$): -->
<!-- - <span class="emphasized">Uncertainty:</span> Ok -->
<!-- - <span class="emphasized">Coherence:</span> Improvement required -->
<!-- <center>![](images/GPFDA_image.png){height=370}</center> -->
<!-- $\rightarrow$ Using the **shared information** between individuals (GPR-ME) -->
<!-- ## The GPFR model -->
<!-- <font size="6">*Shi & Wang - 2008 | Shi & Choi - 2011* </font> -->
<!-- $$y_i(t) = \mu_0(t) + f_i(t) + \epsilon_i$$ -->
<!-- with: -->
<!-- - $\mu_0(t) = \sum\limits_{k =1}^{K} \alpha_k \mathcal{B}_k(t)$ with $(\mathcal{B}_k)_k$ a spline basis -->
<!-- - $f_i(\cdot) \sim \mathcal{GP}(0, \Sigma_{\theta_i}(\cdot,\cdot)), \ f_i \perp \!\!\! \perp$ -->
<!-- - $\epsilon_i \sim \mathcal{N}(0, \sigma_i^2), \ \epsilon_i \perp \!\!\! \perp$ -->
<!-- <span class="emphasized">GPFDA R package</span> -->
<!-- **Limits:** -->
<!-- - No uncertainty about $\mu_0$ -->
<!-- - Does not allow irregular time series -->
<!-- ## Multi-task Gaussian processes with common mean (MAGMA) -->
<!-- $$y_i(t) = \mu_0(t) + f_i(t) + \epsilon_i$$ -->
<!-- with: -->
<!-- - $\mu_0(\cdot) \sim \mathcal{GP}(m_0(\cdot), K_{\theta_0}(\cdot,\cdot))$ -->
<!-- - $f_i(\cdot) \sim \mathcal{GP}(0, \Sigma_{\theta_i}(\cdot,\cdot)), \ f_i \perp \!\!\! \perp$ -->
<!-- - $\epsilon_i \sim \mathcal{N}(0, \sigma_i^2), \ \epsilon_i \perp \!\!\! \perp$ -->
<!-- It follows that: -->
<!-- $$y_i(\cdot) \vert \mu_0 \sim \mathcal{GP}(\mu_0(\cdot),   \Sigma_{\theta_i}(\cdot,\cdot) + \sigma_i^2), \ y_i \vert \mu_0 \perp \!\!\! \perp$$ -->
<!-- $\rightarrow$ Shared information through $\mu_0$ and its uncertainty -->
<!-- $\rightarrow$ Unified non parametric probabilistic framework -->
<!-- $\rightarrow$ Effective even for irregular time series -->
<!-- ## Notations -->
<!-- $\textbf{y} = (y_1^1,\dots,y_i^k,\dots,y_M^{N_M})^T$ -->
<!-- $\textbf{t} = (t_1^1,\dots,t_i^k,\dots,t_M^{N_M})^T$ -->
<!-- $\Theta = \{ \theta_0, (\theta_i)_i, \sigma_i^2 \}$ -->
<!-- $K$: covariance matrix from the process $\mu_0$ evaluated on $\textbf{t}$ -->
<!-- $K = \left[ K_{\theta_0}(t_i^k, t_j^l) \right]_{(i,j), (k,l)}$ -->
<!-- $\Sigma_i$: covariance matrix from the process $f_i$ evaluated on $\textbf{t}_i$ -->
<!-- $\Sigma_i = \left[ \Sigma_{\theta_i}(t_i^k, t_i^l) \right]_{(k,l)} \ \ \forall i = 1, \dots, M$ -->
<!-- $\Psi_i = \Sigma_i + \sigma_i^2 I_{N_i}$ -->
<!-- ## Bayes' law is the new black -->
<!-- Reminder of its simple definition: -->
<!-- $$ \mathbb{P}(T \vert D) = \dfrac{\mathbb{P}(D \vert T) \mathbb{P}(T)}{\mathbb{P}(D)}  $$ -->
<!-- Powerful implication when it comes to learning from data: -->
<!-- - $\mathbb{P}(T)$, probability of your theory, what you think **a priori** -->
<!-- - $\mathbb{P}(D \vert T)$, probability of data if theory is true, **likelihood** -->
<!-- - $\mathbb{P}(D)$, probability that your data occur, norm. **constant** -->
<!-- Bayes' law tells you how  and what you should learn on theory T according to data D: -->
<!-- $\rightarrow \mathbb{P}(T \vert D)$, what you should think **a posteriori** -->
<!-- Computational burden, among solutions: **empirical Bayes** -->
<!-- ## Learning HPs and $\mu_0$ : an EM algorithm -->
<!-- <span class="emphasized">Step E:</span> Computing the posterior (knowing $\Theta$) -->
<!-- $$ -->
<!-- \begin{align} -->
<!--   p(\mu_0(\textbf{t}) \vert \textbf{t}, \textbf{y}, \Theta) -->
<!--   &\propto  p(\textbf{y} \vert \textbf{t}, \mu_0(\textbf{t}), \Theta) \ p(\mu_0(\textbf{t}) \vert \textbf{t}, \Theta)   \\ -->
<!--   &\propto \prod\limits_{i =1}^M \mathcal{N}( \mu_0(\textbf{t}_i), \Psi_i)  \ \mathcal{N}(m_0(\textbf{t}), K) \\ -->
<!--   &= [Insert \ here \ some \ PhD \ student \ ideas] \\ -->
<!--   &= \mathcal{N}( \hat{m}_0(\textbf{t}), \hat{K}) -->
<!-- \end{align} -->
<!-- $$ -->
<!-- <span class="emphasized">Step M:</span> Estimating $\Theta$ (knowing $p(\mu_0)$) -->
<!-- $$\hat{\Theta} = \underset{\Theta}{\arg\max} \ \mathbb{E}_{\mu_0} [ \log \ p(\textbf{y}, \mu_0(\textbf{t}) \vert \textbf{t}, \Theta ) \ \vert \Theta]$$ -->
<!-- ```{r, echo = T, eval= F} -->
<!--     Initialize hyperparameters -->
<!--     while(sufficient condition of convergence){ -->
<!--     Iterate alternatively steps E and M} -->
<!-- ```` -->
<!-- ## A picture is worth 1000 words -->
<!-- $\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}$ -->
<!-- <center>![](images/train_it_0.png){height=450}</center> -->
<!-- *Iteration counter* : **0** -->
<!-- ## A picture is worth 1000 words -->
<!-- $\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}$ -->
<!-- <center>![](images/train_it_1.png){height=450}</center> -->
<!-- *Iteration counter* : **1** -->
<!-- ## A picture is worth 1000 words -->
<!-- $\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}$ -->
<!-- <center>![](images/train_it_2.png){height=450}</center> -->
<!-- *Iteration counter* : **2** -->
<!-- ## A picture is worth 1000 words -->
<!-- $\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}$ -->
<!-- <center>![](images/train_it_4.png){height=450}</center> -->
<!-- *Iteration counter* : **4** -->
<!-- ## A picture is worth 1000 words -->
<!-- $\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}$ -->
<!-- <center>![](images/train_it_6.png){height=450}</center> -->
<!-- *Iteration counter* : **6**  $\rightarrow$ *break* and *return* -->
<!-- ## Making predictions -->
<!-- $$ \forall i, \ \ y_i(t) = \mu_0(t) + f_i(t) + \epsilon_i $$ -->
<!-- Suppose that, after the learning step, you observe some data $y_*(\textbf{t}_*)$ from a new individual, and want to make predictions at timestamps $\textbf{t}^p$. -->
<!-- *Multi-task learning* consists in improving performance by **sharing information** across individuals. -->
<!-- Without external information: -->
<!-- $p(\begin{bmatrix} -->
<!--                  y_*^{\textbf{t}_*} \\ -->
<!--                  y_*^{\textbf{t}_p} \\ -->
<!--                \end{bmatrix}) = \mathcal{N}( -->
<!--               \begin{bmatrix} -->
<!--                  \mu_0^{\textbf{t}_*} \\ -->
<!--                  \mu_0^{\textbf{t}^p} \\ -->
<!--                \end{bmatrix}, -->
<!--               \begin{pmatrix} -->
<!--                  \Psi_*^{\textbf{t}_*,\textbf{t}_*} & \Psi_*^{\textbf{t}_*,\textbf{t}^p} \\ -->
<!--                  \Psi_*^{\textbf{t}^p,\textbf{t}_*} & \Psi_*^{\textbf{t}^p,\textbf{t}^p} -->
<!--               \end{pmatrix})$ -->
<!-- ## Making predictions: the key idea -->
<!-- Multi-task regression : **conditioning on other observations** -->
<!-- Incertitude on the mean process : **integrate over $\mu_0$** -->
<!-- $$\begin{align} -->
<!--   p(y_* \vert \textbf{y}) -->
<!--   &= \int p(y_*, \mu_0 \vert \textbf{y}) \ d \mu_0\\ -->
<!--   &\underbrace{=}_{Bayes} \int p(y_* \vert \textbf{y}, \mu_0) p(\mu_0 \vert \textbf{y}) \ d \mu_0 \\ -->
<!--   &\underbrace{=}_{(y_i \vert \mu_0)_i \perp \!\!\! \perp} \int p(y_* \vert \mu_0) p(\mu_0 \vert \textbf{y}) \ d \mu_0 \\ -->
<!--   &= \int \mathcal{N}(y_*; \mu_0, \Psi_*) \mathcal{N}(\mu_0; \hat{m}_0, \hat{K}) \ d \mu_0 \\ -->
<!--   &= \mathcal{N}( \hat{m}_0, \Gamma_* = \Psi_* + \hat{K}) -->
<!-- \end{align}$$ -->
<!-- ## Making predictions: additional steps -->
<!-- - $\hat{\theta}_*, \hat{\sigma}_*^2 =  \underset{\theta_*, \sigma_*^2}{\arg\max} \ \mathbb{E}_{\mu_0} [ \log \ p(\textbf{y}_*(\textbf{t}_*), \mu_0(\textbf{t}_*) \vert \theta_*, \sigma_*^2 )]$ -->
<!-- - Prior: $p(\begin{bmatrix} -->
<!--                  y_*^{\textbf{t}_*} \\ -->
<!--                  y_*^{\textbf{t}_p} \\ -->
<!--                \end{bmatrix} \vert \textbf{y}) = \mathcal{N}( -->
<!--               \begin{bmatrix} -->
<!--                  \hat{m}_0^{\textbf{t}_*} \\ -->
<!--                  \hat{m}_0^{\textbf{t}_p} \\ -->
<!--                \end{bmatrix}, -->
<!--               \begin{pmatrix} -->
<!--                  \Gamma_{**} & \Gamma_{*p} \\ -->
<!--                  \Gamma_{p*} & \Gamma_{pp} -->
<!--               \end{pmatrix})$ -->
<!-- - Posterior: $p(y_*^{\textbf{t}^p}  \vert y_*^{\textbf{t}_*}, \textbf{y}) = \mathcal{N} \Big( \hat{\mu}_{*}^{\textbf{t}^p} , \hat{\Gamma}_{*}^{\textbf{t}^p} \Big)$ -->
<!-- avec: -->
<!-- - $\hat{\mu}_{*}^{\textbf{t}^p} =  \hat{m}_0^{\textbf{t}_p} + \Gamma_{p*}\Gamma_{**}^{-1} (y_*^{\textbf{t}_*} - \hat{m}_0^{\textbf{t}_*})$ -->
<!-- - $\hat{\Gamma}_{*}^{\textbf{t}^p} = \Gamma_{pp} - \Gamma_{p*}\Gamma_{**}^{-1} \Gamma_{*p}$ -->
<!-- ## A GIF is worth $10^9$ words -->
<!-- ![](images/GP_standard.gif){height=450}  ![](images/Our_algo_wide.gif){height=450} -->
<!-- - Same data, same hyperparameters from learning -->
<!-- - Standard GP (left) | MAGMA (right) -->
<!-- ## A GIF is worth $10^9$ words -->
<!-- <center><img src="images/Our_algo_zoom.gif" height = "600" width="700"></center> -->
<!-- ## We talked about clustering, did we ? -->
<!-- A unique underlying mean process might be insufficient -->
<!-- $\rightarrow$ Mixture model of multitask GP: -->
<!-- $$\forall i , \forall k ,  \ \ y_i(t) \vert (Z_{ik} = 1)  = \mu_k(t) + f_i(t) + \epsilon_i$$ -->
<!-- with: -->
<!-- - $Z_{i} \sim \mathcal{M}(1, \boldsymbol{\pi} = (\pi_1, \dots, \pi_K)), \ Z_i \perp \!\!\! \perp$ -->
<!-- - $\mu_k(\cdot) \sim \mathcal{GP}(m_k(\cdot), C_{\gamma_k}(\cdot,\cdot)), \ \mu_k \perp \!\!\! \perp$ -->
<!-- - $f_i(\cdot) \sim \mathcal{GP}(0, \Sigma_{\theta_i}(\cdot,\cdot)), \ f_i \perp \!\!\! \perp$ -->
<!-- - $\epsilon_i \sim \mathcal{N}(0, \sigma_i^2), \ \epsilon_i \perp \!\!\! \perp$ -->
<!-- It follows that: -->
<!-- $$y_i(\cdot) \vert \{ (\mu_k)_k, \boldsymbol{\pi} \} \sim \sum\limits_{k=1}^K{\pi_k \ \mathcal{GP}\Big(\mu_k(\cdot),   \Psi_i(\cdot, \cdot) \Big)}$$ -->
<!-- ## Learning -->
<!-- We need to learn the following quantities: -->
<!-- - $p((\mu_k)_k \vert \textbf{y})$, mean processes' hyper-posteriors -->
<!-- - $p((Z_i)_i \vert \textbf{y})$, clustering variables' hyper-posteriors -->
<!-- - $\Theta = \{ (\gamma_k)_k, (\theta_i)_i, (\sigma_i^2), \boldsymbol{\pi} \}$, the hyper-parameters -->
<!-- Unfortunately $(\mu_k)_k$ and $(Z_i)_i$ are posterior dependent -->
<!-- $\rightarrow$ Variational inference, to maintain closed-form approximations. -->
<!-- For any distribution $q$: -->
<!-- $\log p(\textbf{y} \vert \Theta) = \mathcal{L}(q; \Theta) + KL \big( q \vert \vert p(\boldsymbol{\mu}, \boldsymbol{Z} \vert \textbf{y}, \Theta)\big)$ -->
<!-- Approximation assumption: $q(\boldsymbol{\mu}, \boldsymbol{Z}) = q_{\boldsymbol{\mu}}(\boldsymbol{\mu})q_{\boldsymbol{Z}}(\boldsymbol{Z})$ -->
<!-- $\rightarrow$ $\mathcal{L}(q; \Theta)$ provides a **lower bound** to maximize -->
<!-- ## Variational EM -->
<!-- <span class="emphasized">Step E:</span> Optimize $\mathcal{L}(q; \Theta)$ w.r.t. $q$ -->
<!-- - $\hat{q}_{\boldsymbol{Z}}(\boldsymbol{Z}) = \prod\limits_{i = 1}^M \mathcal{M}(Z_i;1, \boldsymbol{\tau}_i)$ -->
<!-- - $\hat{q}_{\boldsymbol{\mu}}(\boldsymbol{\mu}) = \prod\limits_{k = 1}^K \mathcal{N}(\mu_k;\hat{m}_k, \hat{C}_k)$ -->
<!-- <span class="emphasized">Step M:</span>  Optimize $\mathcal{L}(q; \Theta)$ w.r.t. $\Theta$ -->
<!-- - $\hat{\Theta} = \text{arg}\max\limits_{\Theta} \mathbb{E}_{\boldsymbol{\mu},\boldsymbol{Z}} \left[ \log p(\textbf{y},\boldsymbol{\mu}, \boldsymbol{Z} \vert \Theta)\right]$ -->
<!-- $\rightarrow$ Iterate on these steps until convergence -->
<!-- ## 4 different model assumptions -->
<!-- - $\mathcal{H}_{oo}: \gamma_0 = \gamma_k, \theta_0 = \theta_i, \sigma_0^2 = \sigma_i^2, \ \forall i, \forall k$ -->
<!-- - $\mathcal{H}_{ko}: \gamma_k \neq \gamma_l, \theta_0 = \theta_i, \sigma_0^2 = \sigma_i^2, \ \forall i, \forall k,l$ -->
<!-- - $\mathcal{H}_{oi}: \gamma_0 = \gamma_k, \theta_i \neq \theta_j, \sigma_i^2 \neq \sigma_j^2, \ \forall i,j,  \forall k$ -->
<!-- - $\mathcal{H}_{ki}: \gamma_0 \neq \gamma_k, \theta_0 \neq \theta_i, \sigma_0^2 \neq \sigma_i^2, \ \forall i,j, \forall k,l$ -->
<!-- $\rightarrow$ Allows a multi-task aspect on the covariance structure, and a compromise between number of hyper-parameters and flexibility: -->
<!-- - $\mathcal{H}_{oo}$: 3 hyper-parameters -->
<!-- - $\mathcal{H}_{ko}$: K + 2 hyper-parameters -->
<!-- - $\mathcal{H}_{oa}$: 2M + 1 hyper-parameters -->
<!-- - $\mathcal{H}_{ki}$: 2M + K hyper-parameters -->
<!-- ## Prediction -->
<!-- - EM for estimating $Z_*, \theta_*,$ and $\sigma_*^2$ -->
<!-- - Multi-task prior: $p(\begin{bmatrix} -->
<!--                  y_*^{\textbf{t}_*} \\ -->
<!--                  y_*^{\textbf{t}_p} \\ -->
<!--                \end{bmatrix} \vert Z_{*k}=1 , \textbf{y}) = \mathcal{N}( -->
<!--               \begin{bmatrix} -->
<!--                  \hat{m}_k^{\textbf{t}_*} \\ -->
<!--                  \hat{m}_k^{\textbf{t}_p} \\ -->
<!--                \end{bmatrix}, -->
<!--               \begin{pmatrix} -->
<!--                  \Gamma_{**}^k & \Gamma_{*p}^k \\ -->
<!--                  \Gamma_{p*}^k & \Gamma_{pp}^k -->
<!--               \end{pmatrix}), \forall k$ -->
<!-- - Multi-task posterior: $p(y_*^{\textbf{t}^p}  \vert y_*^{\textbf{t}_*}, Z_{*k} = 1, \textbf{y}) = \mathcal{N} \big( \hat{\mu}_{*k}^{\textbf{t}^p} , \hat{\Gamma}_{*k}^{\textbf{t}^p} \big), \ \forall k$ -->
<!-- - Predictive multi-task GPs mixture: $p(y_*^{\textbf{t}^p} \vert y_*^{\textbf{t}_*}, \textbf{y}) = \sum\limits_{k = 1}^{K} \tau_{*k} \ \mathcal{N} \big( \hat{\mu}_{*k}^{\textbf{t}^p} , \hat{\Gamma}_{*k}^{\textbf{t}^p} \big)$ -->
</section>
<section id="illustration-gp-regression" class="slide level2">
<h2>Illustration: GP regression</h2>
<center>
<img src="images/illu_compare1.png" height="500" />
</center>
</section>
<section id="illustration-magma" class="slide level2">
<h2>Illustration: MAGMA</h2>
<center>
<img src="images/illu_compare2.png" height="500" />
</center>
</section>
<section id="illustration-magmaclust" class="slide level2">
<h2>Illustration: MAGMAclust</h2>
<center>
<img src="images/illu_compare3.png" height="500" />
</center>
</section>
<section id="illustration-magmaclust-1" class="slide level2">
<h2>Illustration: MAGMAclust</h2>
<center>
<img src="images/illu_2_other_clusters.png" height="500" />
</center>
</section>
<section id="estimation-of-the-mean-processes" class="slide level2">
<h2>Estimation of the mean processes</h2>
<center>
<img src="images/shape_cluster.png" height="500" />
</center>
</section>
<section id="clustering-performances" class="slide level2">
<h2>Clustering performances</h2>
<center>
<img src="images/RI_vs_alternatives.png" height="500" />
</center>
</section>
<section id="and-what-about-the-swimmers" class="slide level2">
<h2>And what about the swimmers ?</h2>
<table class=”daTable”>
<tr>
<th>
</th>
<th align="center">
Simu
</th>
<th align="center">
Simu
</th>
<th align="center">
Real data
</th>
<th align="center">
Real data
</th>
</tr>
<tr>
<th>
</th>
<th align="center">
MSE
</th>
<th align="center">
<span class="math inline">\(CI_{95}\)</span>
</th>
<th align="center">
MSE
</th>
<th align="center">
<span class="math inline">\(CI_{95}\)</span>
</th>
</tr>
<tr>
<th align="center">
GP
</th>
<td align="center">
87.5 (151.9)
</th>
<td align="center">
74.0 (32.7)
</th>
<td align="center">
25.3 (97.6)
</th>
<td align="center">
72.7 (37.1)
</th>
</tr>
<tr>
<th align="center">
GPFDA
</th>
<td align="center">
31.8 (49.4)
</td>
<td align="center">
90.4 (18.1)
</td>
<td>
</th>
<td>
</th>
</tr>
<tr>
<th align="center">
MAGMA
</th>
<td align="center">
<strong>18.7 (31.4)</strong>
</td>
<td align="center">
<strong>93.8 (13.5)</strong>
</td>
<td align="center">
<strong>3.8 (10.3)</strong>
</th>
<td align="center">
<strong>95.3 (15.9)</strong>
</th>
</tr>
</table>
<center>
<img src="images/Figure_4_bis.png" height="400" />
</center>
</section>
<section id="did-i-mention-that-i-like-gifs" class="slide level2">
<h2>Did I mention that I like GIFs ?</h2>
<center>
<img src="images/pred_clust.gif" height = "600" width="700">
</center>
</section>
<section id="why-probabilistic-predictions-matter" class="slide level2">
<h2>Why probabilistic predictions matter ?</h2>
<p>Making a prediction is <span class="math inline">\(\mathbb{P}(\)</span>saying something wrong<span class="math inline">\() \simeq 1\)</span>.<br />
A probabilistic prediction tells you how much:</p>
<center>
<img src="images/heatmap.png" height="500" />
</center>
</section>
<section id="perspectives" class="slide level2">
<h2>Perspectives</h2>
<p><br></p>
<ul>
<li><p>Enable association with sparse GP approximations</p></li>
<li><p>Extend to multivariate functional regression</p></li>
<li><p>Work on an online version</p></li>
<li><p>Develop a more sophisticated model selection tool</p></li>
<li><p>Integrate to the app and launch tests with FFN</p></li>
<li><p>Listen to other good ideas <em>you</em> are about to give me</p></li>
</ul>
</section>
<section id="references" class="slide level2">
<h2>References</h2>
<section style="text-align: left;">
<font size="5"><em>Pattern Recognition and Machine Learning - Bishop - 2006<br />
Gaussian processes for machine learning - Rasmussen &amp; Williams - 2006<br />
Curve prediction and clustering with mixtures of Gaussian process [...] - Shi &amp; Wang - 2008<br />
Gaussian Process Regression Analysis for Functional Data - Shi &amp; Choi - 2011<br />
Career Performance Trajectories in Track and Field Jumping Events [...] - Boccia &amp; al - 2017<br />
Efficient Bayesian hierarchical functional data analysis [...] - Yang &amp; al - 2017<br />
Excelling at youth level in competitive track and field [...] - Kearney &amp; Hayes - 2018<br />
Functional Data Analysis in Sport Science: Example of Swimmers' [...] - Leroy &amp; al. - 2018<br />
MAGMA: Inference and Prediction with Multi-Task Gaussian Processes - Leroy &amp; al. - preprint Cluster-Specific Predictions with Multi-Task Gaussian Processes - Leroy &amp; al. - preprint </em></font>
</section>
<p><br><br><br><br><br><br><br><br><br><br></p>
</section>
<section id="a-cat-gif-is-priceless" class="slide level2">
<h2>A cat GIF is priceless</h2>
<center>
<img src="images/gif_chat.gif" height="500" />
</center>
</section>
    </div>
  </div>

  <script src="slides_Rouen_files/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="slides_Rouen_files/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: false,
        // Transition style
        transition: 'fade', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        // Optional reveal.js plugins
        dependencies: [
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
