<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="" />
  <meta name="author" content="Arthur LEROY (MAP5 - Université de Paris)" />
  <meta name="author" content="Servane GEY (MAP5 - Université de Paris)" />
  <meta name="author" content="Pierre LATOUCHE (MAP5 - Université de Paris)" />
  <meta name="author" content="Benjamin GUEDJ (INRIA - UCL)" />
  <title>Apprentissage de données fonctionnelles par modèles multi-tâches :    Application à la prédiction de performances sportives</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="slides_Rouen_files/reveal.js-3.3.0.1/css/reveal.css"/>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="slides_Rouen_files/reveal.js-3.3.0.1/css/theme/serif.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>

    <link rel="stylesheet" href="style.css"/>

<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

    
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Apprentissage de données fonctionnelles par modèles multi-tâches : <br> <font size="20"> Application à la prédiction de performances sportives </font></h1>
    <h2 class="author"><br /></h2>
    <h2 class="author">Arthur LEROY (MAP5 - Université de Paris)</h2>
    <h2 class="author">Servane GEY (MAP5 - Université de Paris)</h2>
    <h2 class="author">Pierre LATOUCHE (MAP5 - Université de Paris)</h2>
    <h2 class="author">Benjamin GUEDJ (INRIA - UCL)</h2>
    <h3 class="date">Groupe de travail en Statistique du LMRS - Rouen - 22/10/2020</h3>
</section>

<section id="context" class="slide level2">
<h2>Context</h2>
<p>Traditional talent identification: <span class="math inline">\(\rightarrow\)</span> <span class="emphasized">Best young athlete + coach intuition </span></p>
<p><br> G. Boccia et al. (2017) :</p>
<blockquote>
<p><span class="math inline">\(\simeq\)</span> <strong>60% of 16 years old elite athletes</strong> do not maintain their level of performance</p>
</blockquote>
<p>Philip E. Kearney &amp; Philip R. Hayes (2018) :</p>
<blockquote>
<p><span class="math inline">\(\simeq\)</span> <strong>only 10% </strong> of senior top 20 were also top 20 before 13 years</p>
</blockquote>
</section>
<section id="data" class="slide level2">
<h2>Data</h2>
<p>Performances from FF of Swimming members since 2002:</p>
<ul>
<li><strong>Irregular</strong> time series</li>
<li>Different number <span class="math inline">\(N_i\)</span> of observations between individuals</li>
<li>Different observational timestamps <span class="math inline">\(t_i^k\)</span></li>
<li><font color='green'><span class="math inline">\(N_i\)</span></font> <span class="math inline">\(\simeq x \times10^1\)</span>
<center>
<img src="images/data1.png" width="580" />
</center></li>
</ul>
</section>
<section id="data-1" class="slide level2">
<h2>Data</h2>
<p>Performances from FF of Swimming members since 2002:</p>
<ul>
<li><strong>Irregular</strong> time series</li>
<li>Different number <span class="math inline">\(N_i\)</span> of observations between individuals</li>
<li>Different observational timestamps <span class="math inline">\(t_i^k\)</span></li>
<li><font color='green'><span class="math inline">\(N_i\)</span></font> <span class="math inline">\(\simeq x \times10^1\)</span> | <font color='red'><span class="math inline">\(N\)</span></font> <span class="math inline">\(= \sum\limits_{i=1}^{M}\)</span> <font color='green'><span class="math inline">\(N_i\)</span></font> <span class="math inline">\(\simeq x \times 10^5\)</span></li>
</ul>
<center>
<img src="images/data2.png" width="580" />
</center>
</section>
<section id="data-2" class="slide level2">
<h2>Data</h2>
<p>Performances from FF of Swimming members since 2002:</p>
<ul>
<li><strong>Irregular</strong> time series</li>
<li>Different number <span class="math inline">\(N_i\)</span> of observations between individuals</li>
<li>Different observational timestamps <span class="math inline">\(t_i^k\)</span></li>
<li><font color='green'><span class="math inline">\(N_i\)</span></font> <span class="math inline">\(\simeq x \times10^1\)</span> | <font color='red'><span class="math inline">\(N\)</span></font> <span class="math inline">\(= \sum\limits_{i=1}^{M}\)</span> <font color='green'><span class="math inline">\(N_i\)</span></font> <span class="math inline">\(\simeq x \times 10^5\)</span></li>
</ul>
<center>
<img src="images/data3.png" width="580" />
</center>
</section>
<section id="curves-clustering" class="slide level2">
<h2>Curves clustering</h2>
<p>Functional data <span class="math inline">\(\simeq\)</span> coefficients <span class="math inline">\(\alpha_k\)</span> of B-splines functions:</p>
<p><span class="math display">\[y_i(t) = \sum\limits_{k=1}^{K}{\alpha_k B_k(t)}\]</span></p>
<p><span class="emphasized">Clustering:</span> Algo <strong>FunHDDC</strong> (Gaussian mixture + EM) <em>Bouveyron &amp; Jacques - 2011</em></p>
<p><br> Using the multidimensional version : curve + derivative <span class="math inline">\(\rightarrow\)</span> Information about performance <strong>level</strong> and <strong>trend</strong> of improvement</p>
</section>
<section id="curve-clustering" class="slide level2">
<h2>Curve clustering</h2>
<p><em>Leroy et al. - 2018</em></p>
<ul>
<li>Different patterns of progression</li>
<li>Consistent groups for sports experts</li>
</ul>
<center>
<img src="images/multclust_all.png" width="920" height="450" />
</center>
</section>
<section id="curve-clustering-1" class="slide level2">
<h2>Curve clustering</h2>
<p><em>Leroy et al. - 2018</em></p>
<ul>
<li>Different patterns of progression</li>
<li>Consistent groups for sport experts</li>
</ul>
<center>
<img src="images/multclust.png" width="920" height="450" />
</center>
</section>
<section id="new-objectives" class="slide level2">
<h2>New objectives</h2>
<ul>
<li>Prediction of the future values of the progression curve <span class="math inline">\(\rightarrow\)</span> Functional regression</li>
<li>Quantification of prediction uncertainty <span class="math inline">\(\rightarrow\)</span> Probabilistic framework</li>
</ul>
<center>
<img src="images/gpfda_unique.png" width="600" />
</center>
</section>
<section id="gaussian-process-regression" class="slide level2">
<h2>Gaussian process regression</h2>
<p><em>Bishop - 2006 | Rasmussen &amp; Williams - 2006</em></p>
<p>GPR : a kernel method to estimate <span class="math inline">\(f\)</span> when:</p>
<p><span class="math display">\[y = f(x) +\epsilon\]</span></p>
<p><span class="math inline">\(\rightarrow\)</span> <strong>No restrictions</strong> on <span class="math inline">\(f\)</span> but a <strong>prior probability</strong>:</p>
<p><span class="math display">\[f \sim \mathcal{GP}(0,C(\cdot,\cdot))\]</span></p>
<p><em>An example of exponential kernel for the covariance function:</em> <span class="math display">\[cov(f(x),f(x&#39;))= C(x,x&#39;) = \alpha exp(- \dfrac{1}{2\theta^2} |x - x&#39;|^2)\]</span> Kernel definition <span class="math inline">\(\Rightarrow\)</span> <em>prefered</em> properties on <span class="math inline">\(f\)</span></p>
</section>
<section id="prediction" class="slide level2">
<h2>Prediction</h2>
<p><span class="math inline">\(\textbf{y}_{N+1} = (y_1,...,y_{N+1})\)</span> has the following prior density: <span class="math display">\[\textbf{y}_{N+1} \sim \mathcal{N}(0, C_{N+1}), \ C_{N+1} = \begin{pmatrix} C_N &amp; k_{N+1} \\ k_{N+1}^T &amp; c_{N+1} \end{pmatrix}\]</span></p>
<p>When the joint density is gaussian, so does the conditionnal dentisty:</p>
<p><span class="math display">\[y_{N+1}|\textbf{y}_{N}, \textbf{x}_{N+1} \sim \mathcal{N}(k^T \color{red}{C_N^{-1}}\textbf{y}_{N}, c_{N+1}- k_{N+1}^T  \color{red}{C_N^{-1}} k_{N+1})\]</span></p>
<p><br></p>
<ul>
<li><span class="emphasized">Prediction:</span> <span class="math inline">\(\hat{y}_{N+1} = \mathbb{E}[y_{N+1}|\textbf{y}_{N}, \textbf{x}_{N+1}]\)</span></li>
<li><span class="emphasized">Uncertainty:</span> CI with <span class="math inline">\(\mathbb{V}[y_{N+1}|\textbf{y}_{N}, \textbf{x}_{N+1}]\)</span></li>
</ul>
</section>
<section id="visualization-of-gpr" class="slide level2">
<h2>Visualization of GPR</h2>
<center>
<img src="images/GP.png" />
</center>
<p><strong>Key points:</strong></p>
<ul>
<li>Define a covariance function with desirable properties</li>
<li>Non parametric method giving probabilistic predictions</li>
<li>Complexity <span class="math inline">\(O(\color{red}{N^3})\)</span> (inversion of an <span class="math inline">\(\color{red}{N} \times \color{red}{N}\)</span> matrix)</li>
</ul>
</section>
<section id="gp-estimation-from-data" class="slide level2">
<h2>GP estimation from data</h2>
<p>Estimating a GP on each individual (<span class="math inline">\(O(\color{green}{N_i^3})\)</span>):</p>
<ul>
<li><span class="emphasized">Uncertainty:</span> Ok</li>
</ul>
<center>
<img src="images/gpfda_1pts.png" height="500" />
</center>
</section>
<section id="gp-estimation-from-data-1" class="slide level2">
<h2>GP estimation from data</h2>
<p>Estimating a GP on each individuals (<span class="math inline">\(O(\color{green}{N_i^3})\)</span>):</p>
<ul>
<li><span class="emphasized">Uncertainty:</span> Ok</li>
</ul>
<center>
<img src="images/gpfda_5pts.png" height="500" />
</center>
</section>
<section id="gp-estimation-from-data-2" class="slide level2">
<h2>GP estimation from data</h2>
<p>Estimating a GP on each individuals (<span class="math inline">\(O(\color{green}{N_i^3})\)</span>):</p>
<ul>
<li><span class="emphasized">Uncertainty:</span> Ok</li>
</ul>
<center>
<img src="images/gpfda_10pts.png" height="500" />
</center>
</section>
<section id="gp-estimation-from-data-3" class="slide level2">
<h2>GP estimation from data</h2>
<p>Estimating a GP on each individuals (<span class="math inline">\(O(\color{green}{N_i^3})\)</span>):</p>
<ul>
<li><span class="emphasized">Uncertainty:</span> Ok</li>
</ul>
<center>
<img src="images/gpfda_15pts.png" height="500" />
</center>
</section>
<section id="gp-estimation-from-data-4" class="slide level2">
<h2>GP estimation from data</h2>
<p>Estimating a GP on each individuals (<span class="math inline">\(O(\color{green}{N_i^3})\)</span>):</p>
<ul>
<li><span class="emphasized">Uncertainty:</span> Ok</li>
</ul>
<center>
<img src="images/gpfda_totalpts.png" height="500" />
</center>
</section>
<section id="reaching-a-coherent-modeling" class="slide level2">
<h2>Reaching a coherent modeling</h2>
<p>Estimating a GP on each individuals (<span class="math inline">\(O(\color{green}{N_i^3})\)</span>):</p>
<ul>
<li><span class="emphasized">Uncertainty:</span> Ok</li>
<li><span class="emphasized">Coherence:</span> Improvement required</li>
</ul>
<center>
<img src="images/GPFDA_image.png" height="370" />
</center>
<p><span class="math inline">\(\rightarrow\)</span> Using the <strong>shared information</strong> between individuals (GPR-ME)</p>
</section>
<section id="the-gpfr-model" class="slide level2">
<h2>The GPFR model</h2>
<p><font size="6"><em>Shi &amp; Wang - 2008 | Shi &amp; Choi - 2011</em> </font></p>
<p><span class="math display">\[y_i(t) = \mu_0(t) + f_i(t) + \epsilon_i\]</span> with:</p>
<ul>
<li><span class="math inline">\(\mu_0(t) = \sum\limits_{k =1}^{K} \alpha_k \mathcal{B}_k(t)\)</span> with <span class="math inline">\((\mathcal{B}_k)_k\)</span> a spline basis</li>
<li><span class="math inline">\(f_i(\cdot) \sim \mathcal{GP}(0, \Sigma_{\theta_i}(\cdot,\cdot)), \ f_i \perp \!\!\! \perp\)</span></li>
<li><span class="math inline">\(\epsilon_i \sim \mathcal{N}(0, \sigma_i^2), \ \epsilon_i \perp \!\!\! \perp\)</span></li>
</ul>
<p><span class="emphasized">GPFDA R package</span></p>
<p><strong>Limits:</strong></p>
<ul>
<li>No uncertainty about <span class="math inline">\(\mu_0\)</span></li>
<li>Does not allow irregular time series</li>
</ul>
</section>
<section id="multi-task-gaussian-processes-with-common-mean-magma" class="slide level2">
<h2>Multi-task Gaussian processes with common mean (MAGMA)</h2>
<p><span class="math display">\[y_i(t) = \mu_0(t) + f_i(t) + \epsilon_i\]</span> with:</p>
<ul>
<li><span class="math inline">\(\mu_0(\cdot) \sim \mathcal{GP}(m_0(\cdot), K_{\theta_0}(\cdot,\cdot))\)</span></li>
<li><span class="math inline">\(f_i(\cdot) \sim \mathcal{GP}(0, \Sigma_{\theta_i}(\cdot,\cdot)), \ f_i \perp \!\!\! \perp\)</span></li>
<li><span class="math inline">\(\epsilon_i \sim \mathcal{N}(0, \sigma_i^2), \ \epsilon_i \perp \!\!\! \perp\)</span></li>
</ul>
<p>It follows that:</p>
<p><span class="math display">\[y_i(\cdot) \vert \mu_0 \sim \mathcal{GP}(\mu_0(\cdot),   \Sigma_{\theta_i}(\cdot,\cdot) + \sigma_i^2), \ y_i \vert \mu_0 \perp \!\!\! \perp\]</span></p>
<p><span class="math inline">\(\rightarrow\)</span> Shared information through <span class="math inline">\(\mu_0\)</span> and its uncertainty <span class="math inline">\(\rightarrow\)</span> Unified non parametric probabilistic framework <span class="math inline">\(\rightarrow\)</span> Effective even for irregular time series</p>
</section>
<section id="notations" class="slide level2">
<h2>Notations</h2>
<p><span class="math inline">\(\textbf{y} = (y_1^1,\dots,y_i^k,\dots,y_M^{N_M})^T\)</span> <span class="math inline">\(\textbf{t} = (t_1^1,\dots,t_i^k,\dots,t_M^{N_M})^T\)</span> <span class="math inline">\(\Theta = \{ \theta_0, (\theta_i)_i, \sigma_i^2 \}\)</span></p>
<p><span class="math inline">\(K\)</span>: covariance matrix from the process <span class="math inline">\(\mu_0\)</span> evaluated on <span class="math inline">\(\textbf{t}\)</span></p>
<p><span class="math inline">\(K = \left[ K_{\theta_0}(t_i^k, t_j^l) \right]_{(i,j), (k,l)}\)</span></p>
<p><span class="math inline">\(\Sigma_i\)</span>: covariance matrix from the process <span class="math inline">\(f_i\)</span> evaluated on <span class="math inline">\(\textbf{t}_i\)</span></p>
<p><span class="math inline">\(\Sigma_i = \left[ \Sigma_{\theta_i}(t_i^k, t_i^l) \right]_{(k,l)} \ \ \forall i = 1, \dots, M\)</span></p>
<p><span class="math inline">\(\Psi_i = \Sigma_i + \sigma_i^2 I_{N_i}\)</span></p>
</section>
<section id="bayes-law-is-the-new-black" class="slide level2">
<h2>Bayes' law is the new black</h2>
<p>Reminder of its simple definition:</p>
<p><span class="math display">\[ \mathbb{P}(T \vert D) = \dfrac{\mathbb{P}(D \vert T) \mathbb{P}(T)}{\mathbb{P}(D)}  \]</span> Powerful implication when it comes to learning from data:</p>
<ul>
<li><span class="math inline">\(\mathbb{P}(T)\)</span>, probability of your theory, what you think <strong>a priori</strong></li>
<li><span class="math inline">\(\mathbb{P}(D \vert T)\)</span>, probability of data if theory is true, <strong>likelihood</strong></li>
<li><span class="math inline">\(\mathbb{P}(D)\)</span>, probability that your data occur, norm. <strong>constant</strong></li>
</ul>
<p>Bayes' law tells you how and what you should learn on theory T according to data D:</p>
<p><span class="math inline">\(\rightarrow \mathbb{P}(T \vert D)\)</span>, what you should think <strong>a posteriori</strong> Computational burden, among solutions: <strong>empirical Bayes</strong></p>
</section>
<section id="learning-hps-and-mu_0-an-em-algorithm" class="slide level2">
<h2>Learning HPs and <span class="math inline">\(\mu_0\)</span> : an EM algorithm</h2>
<p><span class="emphasized">Step E:</span> Computing the posterior (knowing <span class="math inline">\(\Theta\)</span>)</p>
<p><span class="math display">\[
\begin{align}
  p(\mu_0(\textbf{t}) \vert \textbf{t}, \textbf{y}, \Theta)
  &amp;\propto  p(\textbf{y} \vert \textbf{t}, \mu_0(\textbf{t}), \Theta) \ p(\mu_0(\textbf{t}) \vert \textbf{t}, \Theta)   \\
  &amp;\propto \prod\limits_{i =1}^M \mathcal{N}( \mu_0(\textbf{t}_i), \Psi_i)  \ \mathcal{N}(m_0(\textbf{t}), K) \\
  &amp;= [Insert \ here \ some \ PhD \ student \ ideas] \\
  &amp;= \mathcal{N}( \hat{m}_0(\textbf{t}), \hat{K})
\end{align}
\]</span></p>
<p><span class="emphasized">Step M:</span> Estimating <span class="math inline">\(\Theta\)</span> (knowing <span class="math inline">\(p(\mu_0)\)</span>)</p>
<p><span class="math display">\[\hat{\Theta} = \underset{\Theta}{\arg\max} \ \mathbb{E}_{\mu_0} [ \log \ p(\textbf{y}, \mu_0(\textbf{t}) \vert \textbf{t}, \Theta ) \ \vert \Theta]\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    Initialize hyperparameters
    <span class="cf">while</span>(sufficient condition of convergence){
    Iterate alternatively steps E and M}</code></pre></div>
</section>
<section id="a-picture-is-worth-1000-words" class="slide level2">
<h2>A picture is worth 1000 words</h2>
<p><span class="math inline">\(\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}\)</span></p>
<center>
<img src="images/train_it_0.png" height="450" />
</center>
<p><em>Iteration counter</em> : <strong>0</strong></p>
</section>
<section id="a-picture-is-worth-1000-words-1" class="slide level2">
<h2>A picture is worth 1000 words</h2>
<p><span class="math inline">\(\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}\)</span></p>
<center>
<img src="images/train_it_1.png" height="450" />
</center>
<p><em>Iteration counter</em> : <strong>1</strong></p>
</section>
<section id="a-picture-is-worth-1000-words-2" class="slide level2">
<h2>A picture is worth 1000 words</h2>
<p><span class="math inline">\(\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}\)</span></p>
<center>
<img src="images/train_it_2.png" height="450" />
</center>
<p><em>Iteration counter</em> : <strong>2</strong></p>
</section>
<section id="a-picture-is-worth-1000-words-3" class="slide level2">
<h2>A picture is worth 1000 words</h2>
<p><span class="math inline">\(\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}\)</span></p>
<center>
<img src="images/train_it_4.png" height="450" />
</center>
<p><em>Iteration counter</em> : <strong>4</strong></p>
</section>
<section id="a-picture-is-worth-1000-words-4" class="slide level2">
<h2>A picture is worth 1000 words</h2>
<p><span class="math inline">\(\mathbb{E} \left[ \mu_0(\textbf{t}) \vert Data \right] \pm CI_{0.95}\)</span></p>
<center>
<img src="images/train_it_6.png" height="450" />
</center>
<p><em>Iteration counter</em> : <strong>6</strong> <span class="math inline">\(\rightarrow\)</span> <em>break</em> and <em>return</em></p>
</section>
<section id="making-predictions" class="slide level2">
<h2>Making predictions</h2>
<p><span class="math display">\[ \forall i, \ \ y_i(t) = \mu_0(t) + f_i(t) + \epsilon_i \]</span></p>
<p>Suppose that, after the learning step, you observe some data <span class="math inline">\(y_*(\textbf{t}_*)\)</span> from a new individual, and want to make predictions at timestamps <span class="math inline">\(\textbf{t}^p\)</span>.</p>
<p><em>Multi-task learning</em> consists in improving performance by <strong>sharing information</strong> across individuals.</p>
<p>Without external information:</p>
<p><span class="math inline">\(p(\begin{bmatrix}  y_*^{\textbf{t}_*} \\  y_*^{\textbf{t}_p} \\  \end{bmatrix}) = \mathcal{N}(  \begin{bmatrix}  \mu_0^{\textbf{t}_*} \\  \mu_0^{\textbf{t}^p} \\  \end{bmatrix},  \begin{pmatrix}  \Psi_*^{\textbf{t}_*,\textbf{t}_*} &amp; \Psi_*^{\textbf{t}_*,\textbf{t}^p} \\  \Psi_*^{\textbf{t}^p,\textbf{t}_*} &amp; \Psi_*^{\textbf{t}^p,\textbf{t}^p}  \end{pmatrix})\)</span></p>
</section>
<section id="making-predictions-the-key-idea" class="slide level2">
<h2>Making predictions: the key idea</h2>
<p>Multi-task regression : <strong>conditioning on other observations</strong> Incertitude on the mean process : <strong>integrate over <span class="math inline">\(\mu_0\)</span></strong></p>
<p><span class="math display">\[\begin{align}
  p(y_* \vert \textbf{y})
  &amp;= \int p(y_*, \mu_0 \vert \textbf{y}) \ d \mu_0\\
  &amp;\underbrace{=}_{Bayes} \int p(y_* \vert \textbf{y}, \mu_0) p(\mu_0 \vert \textbf{y}) \ d \mu_0 \\
  &amp;\underbrace{=}_{(y_i \vert \mu_0)_i \perp \!\!\! \perp} \int p(y_* \vert \mu_0) p(\mu_0 \vert \textbf{y}) \ d \mu_0 \\
  &amp;= \int \mathcal{N}(y_*; \mu_0, \Psi_*) \mathcal{N}(\mu_0; \hat{m}_0, \hat{K}) \ d \mu_0 \\
  &amp;= \mathcal{N}( \hat{m}_0, \Gamma_* = \Psi_* + \hat{K})
\end{align}\]</span></p>
</section>
<section id="making-predictions-additional-steps" class="slide level2">
<h2>Making predictions: additional steps</h2>
<ul>
<li><p><span class="math inline">\(\hat{\theta}_*, \hat{\sigma}_*^2 = \underset{\theta_*, \sigma_*^2}{\arg\max} \ \mathbb{E}_{\mu_0} [ \log \ p(\textbf{y}_*(\textbf{t}_*), \mu_0(\textbf{t}_*) \vert \theta_*, \sigma_*^2 )]\)</span></p></li>
<li><p>Prior: <span class="math inline">\(p(\begin{bmatrix}  y_*^{\textbf{t}_*} \\  y_*^{\textbf{t}_p} \\  \end{bmatrix} \vert \textbf{y}) = \mathcal{N}(  \begin{bmatrix}  \hat{m}_0^{\textbf{t}_*} \\  \hat{m}_0^{\textbf{t}_p} \\  \end{bmatrix},  \begin{pmatrix}  \Gamma_{**} &amp; \Gamma_{*p} \\  \Gamma_{p*} &amp; \Gamma_{pp}  \end{pmatrix})\)</span></p></li>
<li><p>Posterior: <span class="math inline">\(p(y_*^{\textbf{t}^p} \vert y_*^{\textbf{t}_*}, \textbf{y}) = \mathcal{N} \Big( \hat{\mu}_{*}^{\textbf{t}^p} , \hat{\Gamma}_{*}^{\textbf{t}^p} \Big)\)</span></p></li>
</ul>
<p>with:</p>
<ul>
<li><span class="math inline">\(\hat{\mu}_{*}^{\textbf{t}^p} = \hat{m}_0^{\textbf{t}_p} + \Gamma_{p*}\Gamma_{**}^{-1} (y_*^{\textbf{t}_*} - \hat{m}_0^{\textbf{t}_*})\)</span></li>
<li><span class="math inline">\(\hat{\Gamma}_{*}^{\textbf{t}^p} = \Gamma_{pp} - \Gamma_{p*}\Gamma_{**}^{-1} \Gamma_{*p}\)</span></li>
</ul>
</section>
<section id="a-gif-is-worth-109-words" class="slide level2">
<h2>A GIF is worth <span class="math inline">\(10^9\)</span> words</h2>
<p><img src="images/GP_standard.gif" height="450" /> <img src="images/Our_algo_wide.gif" height="450" /></p>
<ul>
<li>Same data, same hyperparameters from learning</li>
<li>Standard GP (left) | MAGMA (right)</li>
</ul>
</section>
<section id="a-gif-is-worth-109-words-1" class="slide level2">
<h2>A GIF is worth <span class="math inline">\(10^9\)</span> words</h2>
<center>
<img src="images/Our_algo_zoom.gif" height = "600" width="700">
</center>
</section>
<section id="we-talked-about-clustering-did-we" class="slide level2">
<h2>We talked about clustering, did we ?</h2>
<p>A unique underlying mean process might be insufficient</p>
<p><span class="math inline">\(\rightarrow\)</span> Mixture model of multitask GP:</p>
<p><span class="math display">\[\forall i , \forall k ,  \ \ y_i(t) \vert (Z_{ik} = 1)  = \mu_k(t) + f_i(t) + \epsilon_i\]</span> with:</p>
<ul>
<li><span class="math inline">\(Z_{i} \sim \mathcal{M}(1, \boldsymbol{\pi} = (\pi_1, \dots, \pi_K)), \ Z_i \perp \!\!\! \perp\)</span></li>
<li><span class="math inline">\(\mu_k(\cdot) \sim \mathcal{GP}(m_k(\cdot), C_{\gamma_k}(\cdot,\cdot)), \ \mu_k \perp \!\!\! \perp\)</span></li>
<li><span class="math inline">\(f_i(\cdot) \sim \mathcal{GP}(0, \Sigma_{\theta_i}(\cdot,\cdot)), \ f_i \perp \!\!\! \perp\)</span></li>
<li><span class="math inline">\(\epsilon_i \sim \mathcal{N}(0, \sigma_i^2), \ \epsilon_i \perp \!\!\! \perp\)</span></li>
</ul>
<p>It follows that:</p>
<p><span class="math display">\[y_i(\cdot) \vert \{ (\mu_k)_k, \boldsymbol{\pi} \} \sim \sum\limits_{k=1}^K{\pi_k \ \mathcal{GP}\Big(\mu_k(\cdot),   \Psi_i(\cdot, \cdot) \Big)}\]</span></p>
</section>
<section id="learning" class="slide level2">
<h2>Learning</h2>
<p>We need to learn the following quantities:</p>
<ul>
<li><span class="math inline">\(p((\mu_k)_k \vert \textbf{y})\)</span>, mean processes' hyper-posteriors</li>
<li><span class="math inline">\(p((Z_i)_i \vert \textbf{y})\)</span>, clustering variables' hyper-posteriors</li>
<li><span class="math inline">\(\Theta = \{ (\gamma_k)_k, (\theta_i)_i, (\sigma_i^2), \boldsymbol{\pi} \}\)</span>, the hyper-parameters</li>
</ul>
<p>Unfortunately <span class="math inline">\((\mu_k)_k\)</span> and <span class="math inline">\((Z_i)_i\)</span> are posterior dependent</p>
<p><span class="math inline">\(\rightarrow\)</span> Variational inference, to maintain closed-form approximations. For any distribution <span class="math inline">\(q\)</span>:</p>
<p><span class="math inline">\(\log p(\textbf{y} \vert \Theta) = \mathcal{L}(q; \Theta) + KL \big( q \vert \vert p(\boldsymbol{\mu}, \boldsymbol{Z} \vert \textbf{y}, \Theta)\big)\)</span></p>
<p>Approximation assumption: <span class="math inline">\(q(\boldsymbol{\mu}, \boldsymbol{Z}) = q_{\boldsymbol{\mu}}(\boldsymbol{\mu})q_{\boldsymbol{Z}}(\boldsymbol{Z})\)</span></p>
<p><span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\mathcal{L}(q; \Theta)\)</span> provides a <strong>lower bound</strong> to maximize</p>
</section>
<section id="variational-em" class="slide level2">
<h2>Variational EM</h2>
<p><span class="emphasized">Step E:</span> Optimize <span class="math inline">\(\mathcal{L}(q; \Theta)\)</span> w.r.t. <span class="math inline">\(q\)</span></p>
<ul>
<li><p><span class="math inline">\(\hat{q}_{\boldsymbol{Z}}(\boldsymbol{Z}) = \prod\limits_{i = 1}^M \mathcal{M}(Z_i;1, \boldsymbol{\tau}_i)\)</span></p></li>
<li><p><span class="math inline">\(\hat{q}_{\boldsymbol{\mu}}(\boldsymbol{\mu}) = \prod\limits_{k = 1}^K \mathcal{N}(\mu_k;\hat{m}_k, \hat{C}_k)\)</span></p></li>
</ul>
<p><span class="emphasized">Step M:</span> Optimize <span class="math inline">\(\mathcal{L}(q; \Theta)\)</span> w.r.t. <span class="math inline">\(\Theta\)</span></p>
<ul>
<li><span class="math inline">\(\hat{\Theta} = \text{arg}\max\limits_{\Theta} \mathbb{E}_{\boldsymbol{\mu},\boldsymbol{Z}} \left[ \log p(\textbf{y},\boldsymbol{\mu}, \boldsymbol{Z} \vert \Theta)\right]\)</span></li>
</ul>
<p><span class="math inline">\(\rightarrow\)</span> Iterate on these steps until convergence</p>
</section>
<section id="different-model-assumptions" class="slide level2">
<h2>4 different model assumptions</h2>
<ul>
<li><span class="math inline">\(\mathcal{H}_{oo}: \gamma_0 = \gamma_k, \theta_0 = \theta_i, \sigma_0^2 = \sigma_i^2, \ \forall i, \forall k\)</span></li>
<li><span class="math inline">\(\mathcal{H}_{ko}: \gamma_k \neq \gamma_l, \theta_0 = \theta_i, \sigma_0^2 = \sigma_i^2, \ \forall i, \forall k,l\)</span></li>
<li><span class="math inline">\(\mathcal{H}_{oi}: \gamma_0 = \gamma_k, \theta_i \neq \theta_j, \sigma_i^2 \neq \sigma_j^2, \ \forall i,j, \forall k\)</span></li>
<li><span class="math inline">\(\mathcal{H}_{ki}: \gamma_0 \neq \gamma_k, \theta_0 \neq \theta_i, \sigma_0^2 \neq \sigma_i^2, \ \forall i,j, \forall k,l\)</span></li>
</ul>
<p><span class="math inline">\(\rightarrow\)</span> Allows a multi-task aspect on the covariance structure, and a compromise between number of hyper-parameters and flexibility:</p>
<ul>
<li><span class="math inline">\(\mathcal{H}_{oo}\)</span>: 3 hyper-parameters</li>
<li><span class="math inline">\(\mathcal{H}_{ko}\)</span>: K + 2 hyper-parameters</li>
<li><span class="math inline">\(\mathcal{H}_{oa}\)</span>: 2M + 1 hyper-parameters</li>
<li><span class="math inline">\(\mathcal{H}_{ki}\)</span>: 2M + K hyper-parameters</li>
</ul>
</section>
<section id="prediction-1" class="slide level2">
<h2>Prediction</h2>
<ul>
<li><p>EM for estimating <span class="math inline">\(Z_*, \theta_*,\)</span> and <span class="math inline">\(\sigma_*^2\)</span></p></li>
<li><p>Multi-task prior: <span class="math inline">\(p(\begin{bmatrix}  y_*^{\textbf{t}_*} \\  y_*^{\textbf{t}_p} \\  \end{bmatrix} \vert Z_{*k}=1 , \textbf{y}) = \mathcal{N}(  \begin{bmatrix}  \hat{m}_k^{\textbf{t}_*} \\  \hat{m}_k^{\textbf{t}_p} \\  \end{bmatrix},  \begin{pmatrix}  \Gamma_{**}^k &amp; \Gamma_{*p}^k \\  \Gamma_{p*}^k &amp; \Gamma_{pp}^k  \end{pmatrix}), \forall k\)</span></p></li>
<li><p>Multi-task posterior: <span class="math inline">\(p(y_*^{\textbf{t}^p} \vert y_*^{\textbf{t}_*}, Z_{*k} = 1, \textbf{y}) = \mathcal{N} \big( \hat{\mu}_{*k}^{\textbf{t}^p} , \hat{\Gamma}_{*k}^{\textbf{t}^p} \big), \ \forall k\)</span></p></li>
<li><p>Predictive multi-task GPs mixture: <span class="math inline">\(p(y_*^{\textbf{t}^p} \vert y_*^{\textbf{t}_*}, \textbf{y}) = \sum\limits_{k = 1}^{K} \tau_{*k} \ \mathcal{N} \big( \hat{\mu}_{*k}^{\textbf{t}^p} , \hat{\Gamma}_{*k}^{\textbf{t}^p} \big)\)</span></p></li>
</ul>
</section>
<section id="illustration-gp-regression" class="slide level2">
<h2>Illustration: GP regression</h2>
<center>
<img src="images/illu_compare1.png" height="500" />
</center>
</section>
<section id="illustration-magma" class="slide level2">
<h2>Illustration: MAGMA</h2>
<center>
<img src="images/illu_compare2.png" height="500" />
</center>
</section>
<section id="illustration-magmaclust" class="slide level2">
<h2>Illustration: MAGMAclust</h2>
<center>
<img src="images/illu_compare3.png" height="500" />
</center>
</section>
<section id="illustration-magmaclust-1" class="slide level2">
<h2>Illustration: MAGMAclust</h2>
<center>
<img src="images/illu_2_other_clusters.png" height="500" />
</center>
</section>
<section id="estimation-of-the-mean-processes" class="slide level2">
<h2>Estimation of the mean processes</h2>
<center>
<img src="images/shape_cluster.png" height="500" />
</center>
</section>
<section id="clustering-performances" class="slide level2">
<h2>Clustering performances</h2>
<center>
<img src="images/RI_vs_alternatives.png" height="500" />
</center>
</section>
<section id="and-what-about-the-swimmers" class="slide level2">
<h2>And what about the swimmers ?</h2>
<table class=”daTable”>
<tr>
<th>
</th>
<th align="center">
Simu
</th>
<th align="center">
Simu
</th>
<th align="center">
Real data
</th>
<th align="center">
Real data
</th>
</tr>
<tr>
<th>
</th>
<th align="center">
MSE
</th>
<th align="center">
<span class="math inline">\(CI_{95}\)</span>
</th>
<th align="center">
MSE
</th>
<th align="center">
<span class="math inline">\(CI_{95}\)</span>
</th>
</tr>
<tr>
<th align="center">
GP
</th>
<td align="center">
87.5 (151.9)
</th>
<td align="center">
74.0 (32.7)
</th>
<td align="center">
25.3 (97.6)
</th>
<td align="center">
72.7 (37.1)
</th>
</tr>
<tr>
<th align="center">
GPFDA
</th>
<td align="center">
31.8 (49.4)
</td>
<td align="center">
90.4 (18.1)
</td>
<td>
</th>
<td>
</th>
</tr>
<tr>
<th align="center">
MAGMA
</th>
<td align="center">
<strong>18.7 (31.4)</strong>
</td>
<td align="center">
<strong>93.8 (13.5)</strong>
</td>
<td align="center">
<strong>3.8 (10.3)</strong>
</th>
<td align="center">
<strong>95.3 (15.9)</strong>
</th>
</tr>
</table>
<center>
<img src="images/Figure_4_bis.png" height="400" />
</center>
</section>
<section id="did-i-mention-that-i-like-gifs" class="slide level2">
<h2>Did I mention that I like GIFs ?</h2>
<center>
<img src="images/gif_heatmap.gif" height = "600" width="700">
</center>
</section>
<section id="why-probabilistic-predictions-matter" class="slide level2">
<h2>Why probabilistic predictions matter ?</h2>
<p>Making a prediction is <span class="math inline">\(\mathbb{P}(\)</span>saying something wrong<span class="math inline">\() \simeq 1\)</span>.<br />
A probabilistic prediction tells you how much:</p>
<center>
<img src="images/heatmap.png" height="500" />
</center>
</section>
<section id="perspectives" class="slide level2">
<h2>Perspectives</h2>
<p><br></p>
<ul>
<li><p>Enable association with sparse GP approximations</p></li>
<li><p>Extend to multivariate functional regression</p></li>
<li><p>Work on an online version</p></li>
<li><p>Develop a more sophisticated model selection tool</p></li>
<li><p>Integrate to the app and launch tests with FFN</p></li>
<li><p>Listen to new good ideas that <em>you</em> are about to give me</p></li>
</ul>
</section>
<section id="references" class="slide level2">
<h2>References</h2>
<section style="text-align: left;">
<font size="5"><em>Pattern Recognition and Machine Learning - Bishop - 2006<br />
Gaussian processes for machine learning - Rasmussen &amp; Williams - 2006<br />
Curve prediction and clustering with mixtures of Gaussian process [...] - Shi &amp; Wang - 2008<br />
Gaussian Process Regression Analysis for Functional Data - Shi &amp; Choi - 2011<br />
Career Performance Trajectories in Track and Field Jumping Events [...] - Boccia &amp; al - 2017<br />
Efficient Bayesian hierarchical functional data analysis [...] - Yang &amp; al - 2017<br />
Excelling at youth level in competitive track and field [...] - Kearney &amp; Hayes - 2018<br />
Functional Data Analysis in Sport Science: Example of Swimmers' [...] - Leroy &amp; al. - 2018<br />
MAGMA: Inference and Prediction with Multi-Task Gaussian Processes - Leroy &amp; al. - preprint Cluster-Specific Predictions with Multi-Task Gaussian Processes - Leroy &amp; al. - preprint </em></font>
</section>
<p><br><br><br><br><br><br><br><br><br><br></p>
</section>
<section id="a-cat-gif-is-priceless" class="slide level2">
<h2>A cat GIF is priceless</h2>
<center>
<img src="images/gif_chat.gif" height="500" />
</center>
</section>
    </div>
  </div>

  <script src="slides_Rouen_files/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="slides_Rouen_files/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: false,
        // Transition style
        transition: 'fade', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        // Optional reveal.js plugins
        dependencies: [
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
